{
  "paragraphs": [
    {
      "text": "%md\n\n## Accessing MapR-DB in Zeppelin Using the MapR-DB OJAI Connector with Scala\n\nThis section contains examples of Apache Spark Scala jobs that use the MapR-DB OJAI Connector for Apache Spark to read and write MapR-DB JSON tables.",
      "user": "anonymous",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eAccessing MapR-DB in Zeppelin Using the MapR-DB OJAI Connector with Scala\u003c/h2\u003e\n\u003cp\u003eThis section contains examples of Apache Spark Scala jobs that use the MapR-DB OJAI Connector for Apache Spark to read and write MapR-DB JSON tables.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1516899563631_-1405042137",
      "id": "20180125-165923_1084237878",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Load source data to MapR-FS",
      "text": "%sh\nTEMPDIR\u003d$(mktemp -d)\ncd $TEMPDIR\n\n# Spark can not parse JSON file with newlines, so we need to remove newlines from data file using \"tr -d \u0027\\n\u0027\"\ntr -d \u0027\\n\u0027 \u003e ./zeppelin_maprdb_sample.json \u003c\u003cEOF\n[ { \"_id\": \"rsmith\",\n    \"address\": {\"city\": \"San Francisco\", \"line\": \"100 Main Street\", \"zip\": 94105},\n    \"dob\": \"1982-02-03\",\n    \"first_name\": \"Robert\",\n    \"interests\": [\"electronics\", \"music\", \"sports\"],\n    \"last_name\": \"Smith\"\n  },\n  { \"_id\": \"mdupont\",\n    \"address\": {\"city\": \"San Jose\", \"line\": \"1223 Broadway\", \"zip\": 95109},\n    \"dob\": \"1982-02-03\",\n    \"first_name\": \"Maxime\",\n    \"interests\": [\"sports\", \"movies\", \"electronics\"],\n    \"last_name\": \"Dupont\"\n  },\n  { \"_id\": \"jdoe\",\n    \"address\": {\"city\": \"San Francisco\", \"line\": \"12 Main Street\", \"zip\": 94005},\n    \"dob\": \"1970-06-23\",\n    \"first_name\": \"John\",\n    \"interests\": null,\n    \"last_name\": \"Doe\"\n  },\n  { \"_id\": \"dsimon\",\n    \"address\": null,\n    \"dob\": \"1980-10-13\",\n    \"first_name\": \"David\",\n    \"interests\": null,\n    \"last_name\": \"Simon\"\n  },\n  { \"_id\": \"alehmann\",\n    \"address\": null,\n    \"dob\": \"1980-10-13\",\n    \"first_name\": \"Andrew\",\n    \"interests\": [\"html\", \"css\", \"js\"],\n    \"last_name\": \"Lehmann\"\n  }\n]\nEOF\n\nhadoop fs -mkdir -p ./zeppelin/samples/\nif ! hadoop fs -test -e \"./zeppelin/samples/zeppelin_maprdb_sample.json\"; then\n    hadoop fs -put ./zeppelin_maprdb_sample.json ./zeppelin/samples/\nfi",
      "user": "anonymous",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "sh",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/sh",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1516361570822_-1350983083",
      "id": "20180119-113250_1762409024",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Inserting a Spark DataFrame into a MapR-DB JSON Table",
      "text": "%livy\nimport com.mapr.db.spark.sql._\nimport com.mapr.db.MapRDB\n\nval workingDir \u003d \"/user/\" + sc.sparkUser + \"/zeppelin/samples\"\nval samplePath \u003d workingDir + \"/zeppelin_maprdb_sample.json\"\nval tablePath \u003d workingDir + \"/sample_table_json\"\n\nval df \u003d spark.read.json(\"maprfs://\" + samplePath)\n\nif (MapRDB.tableExists(tablePath))\n    MapRDB.deleteTable(tablePath)\n\ndf.saveToMapRDB(tablePath,\n                idFieldPath \u003d \"last_name\", // Using idFieldPath argument you can specify non-default field to use as identifier\n                createTable \u003d true)\n\nval result \u003d spark.loadFromMapRDB(tablePath)\nresult.show()",
      "user": "anonymous",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+-------+--------------------+----------+----------+--------------------+---------+\n|    _id|             address|       dob|first_name|           interests|last_name|\n+-------+--------------------+----------+----------+--------------------+---------+\n|    Doe|[San Francisco,12...|1970-06-23|      John|                null|      Doe|\n| Dupont|[San Jose,1223 Br...|1982-02-03|    Maxime|[sports, movies, ...|   Dupont|\n|Lehmann|                null|1980-10-13|    Andrew|     [html, css, js]|  Lehmann|\n|  Simon|                null|1980-10-13|     David|                null|    Simon|\n|  Smith|[San Francisco,10...|1982-02-03|    Robert|[electronics, mus...|    Smith|\n+-------+--------------------+----------+----------+--------------------+---------+"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1516361902738_-62167857",
      "id": "20180119-113822_1630286286",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Inserting a Spark DataFrame into a MapR-DB JSON Table Using Bulk Insert",
      "text": "%livy\nimport com.mapr.db.spark.sql._\nimport com.mapr.db.MapRDB\n\nval workingDir \u003d \"/user/\" + sc.sparkUser + \"/zeppelin/samples\"\nval samplePath \u003d workingDir + \"/zeppelin_maprdb_sample.json\"\nval tablePath \u003d workingDir + \"/sample_table_json\"\n\nval df \u003d spark.read.json(\"maprfs://\" + samplePath).orderBy(\"_id\")\n\nif (MapRDB.tableExists(tablePath))\n    MapRDB.deleteTable(tablePath)\n\ndf.saveToMapRDB(tablePath, createTable \u003d true, bulkInsert \u003d true)\n\nval result \u003d spark.loadFromMapRDB(tablePath)\nresult.show()",
      "user": "anonymous",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/scala",
        "title": true,
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+--------+--------------------+----------+----------+--------------------+---------+\n|     _id|             address|       dob|first_name|           interests|last_name|\n+--------+--------------------+----------+----------+--------------------+---------+\n|alehmann|                null|1980-10-13|    Andrew|     [html, css, js]|  Lehmann|\n|  dsimon|                null|1980-10-13|     David|                null|    Simon|\n|    jdoe|[San Francisco,12...|1970-06-23|      John|                null|      Doe|\n| mdupont|[San Jose,1223 Br...|1982-02-03|    Maxime|[sports, movies, ...|   Dupont|\n|  rsmith|[San Francisco,10...|1982-02-03|    Robert|[electronics, mus...|    Smith|\n+--------+--------------------+----------+----------+--------------------+---------+"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1516899766453_1806931981",
      "id": "20180125-170246_1999217881",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Selecting and Filtering Data when Loading a Spark DataFrame",
      "text": "%livy\nimport com.mapr.db.spark.sql._\nimport com.mapr.db.MapRDB\n\nval workingDir \u003d \"/user/\" + sc.sparkUser + \"/zeppelin/samples\"\nval samplePath \u003d workingDir + \"/zeppelin_maprdb_sample.json\"\nval tablePath \u003d workingDir + \"/sample_table_json\"\n\nval df \u003d spark.read.json(\"maprfs://\" + samplePath)\n\nif (MapRDB.tableExists(tablePath))\n    MapRDB.deleteTable(tablePath)\n\ndf.saveToMapRDB(tablePath, createTable \u003d true)\n\nval result \u003d spark.loadFromMapRDB(tablePath).filter($\"first_name\" \u003d\u003d\u003d \"Maxime\" || $\"address.city\" \u003d\u003d\u003d \"San Francisco\")\nresult.show()",
      "user": "anonymous",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+-------+--------------------+----------+----------+--------------------+---------+\n|    _id|             address|       dob|first_name|           interests|last_name|\n+-------+--------------------+----------+----------+--------------------+---------+\n|   jdoe|[San Francisco,12...|1970-06-23|      John|                null|      Doe|\n|mdupont|[San Jose,1223 Br...|1982-02-03|    Maxime|[sports, movies, ...|   Dupont|\n| rsmith|[San Francisco,10...|1982-02-03|    Robert|[electronics, mus...|    Smith|\n+-------+--------------------+----------+----------+--------------------+---------+"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1516363043460_162168634",
      "id": "20180119-115723_900686396",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Joining DataFrames when Loading a Spark DataFrame",
      "text": "%livy\nimport com.mapr.db.spark.sql._\nimport com.mapr.db.MapRDB\n\nval workingDir \u003d \"/user/\" + sc.sparkUser + \"/zeppelin/samples\"\nval samplePath \u003d workingDir + \"/zeppelin_maprdb_sample.json\"\nval tablePath \u003d workingDir + \"/sample_table_json\"\n\nval df \u003d spark.read.json(\"maprfs://\" + samplePath)\n\nif (MapRDB.tableExists(tablePath))\n    MapRDB.deleteTable(tablePath)\n\ndf.saveToMapRDB(tablePath, createTable \u003d true)\n\nval professions \u003d Seq(\n    (\"rsmith\", \"Engineer\"),\n    (\"alehmann\", \"Accountant\"),\n    (\"alehmann\", \"Doctor\"),\n    (\"fake\", \"Software developer\")\n  )\nval dfProfessions \u003d sc.parallelize(professions).toDF(\"_id\", \"profession\")\n\nval result \u003d spark.loadFromMapRDB(tablePath).join(dfProfessions, \"_id\")\n\nresult.createOrReplaceTempView(\"zeppelin_sample_table\") // Creating TempView to access this data from SparkSQL\n\nresult.show()",
      "user": "anonymous",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+--------+--------------------+----------+----------+--------------------+---------+----------+\n|     _id|             address|       dob|first_name|           interests|last_name|profession|\n+--------+--------------------+----------+----------+--------------------+---------+----------+\n|alehmann|                null|1980-10-13|    Andrew|     [html, css, js]|  Lehmann|Accountant|\n|alehmann|                null|1980-10-13|    Andrew|     [html, css, js]|  Lehmann|    Doctor|\n|  rsmith|[San Francisco,10...|1982-02-03|    Robert|[electronics, mus...|    Smith|  Engineer|\n+--------+--------------------+----------+----------+--------------------+---------+----------+"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1516900036717_791562665",
      "id": "20180125-170716_853131331",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Accessing data with SparkSQL",
      "text": "%livy.sql\n\nSELECT CONCAT(`first_name`, \" \", `last_name`) as name, `profession`, `interests` FROM zeppelin_sample_table",
      "user": "anonymous",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": true,
              "setting": {
                "multiBarChart": {}
              },
              "commonSetting": {},
              "keys": [],
              "groups": [],
              "values": [
                {
                  "name": "address",
                  "index": 1.0,
                  "aggr": "sum"
                }
              ]
            },
            "helium": {}
          }
        },
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/sql",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TABLE",
            "data": "name\tprofession\tinterests\nAndrew Lehmann\tAccountant\t[html, css, js]\nAndrew Lehmann\tDoctor\t[html, css, js]\nRobert Smith\tEngineer\t[electronics, mus..."
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1516906271259_-226212620",
      "id": "20180125-185111_200638054",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "MapR Tutorial/Spark MapR-DB OJAI Connector (Scala)",
  "id": "2D4T6X5AR",
  "angularObjects": {},
  "config": {
    "looknfeel": "default",
    "personalizedMode": "false"
  },
  "info": {}
}
